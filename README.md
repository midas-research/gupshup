# Gupshup
GupShup: Summarizing Open-Domain Code-Switched Conversations EMNLP 2021


### Dataset
Please request for data using this[TBA] Google form. Dataset is available for `Hinglish Dilaogues to English Summarization`(h2e) and  `English Dialogues to English Summarization`(e2e). For each task, Dialogues/conversastion have `.source`(train.source) as file extension whereas Summary has `.target`(train.target) file extension.

## Models
All models weight are uploaded on Huggingface model hub. Either user can directly download these weights in their local and provide this path to `model_name` argument in the scripts or use the provided alias (to `model_name` argument) in scripts directly, this will lead to download weights automatically by scripts. 

Model names are aliased in "gupshup_TASK_MODEL" sense, where "TASK" can be h2e,e2e and MODEL can be mbart,pegasus, etc. as listed below.


**1. Hinglish Dilaogues to English Summary (h2e)**

| Model   | Huggingface Alias                                                             |
|---------|-------------------------------------------------------------------------------|
| mBART   | [midas/gupshup_h2e_mbart](https://huggingface.co/midas/gupshup_h2e_mbart)     |
| PEGASUS | [midas/gupshup_h2e_pegasus](https://huggingface.co/midas/gupshup_h2e_pegasus) |
| T5 MTL  | [midas/gupshup_h2e_t5_mtl](https://huggingface.co/midas/gupshup_h2e_t5_mtl)   |
| T5      | [midas/gupshup_h2e_t5](https://huggingface.co/midas/gupshup_h2e_t5)           |
| BART    | [midas/gupshup_h2e_bart](https://huggingface.co/midas/gupshup_h2e_bart)       |
| GPT-2   | [midas/gupshup_h2e_gpt](https://huggingface.co/midas/gupshup_h2e_gpt)         |


**2. English Dialogues to English Summary (e2e)**

| Model   | Huggingface Alias                                                             |
|---------|-------------------------------------------------------------------------------|
| mBART   | [midas/gupshup_e2e_mbart](https://huggingface.co/midas/gupshup_e2e_mbart)     |
| PEGASUS | [midas/gupshup_e2e_pegasus](https://huggingface.co/midas/gupshup_e2e_pegasus) |
| T5 MTL  | [midas/gupshup_e2e_t5_mtl](https://huggingface.co/midas/gupshup_e2e_t5_mtl)   |
| T5      | [midas/gupshup_e2e_t5](https://huggingface.co/midas/gupshup_e2e_t5)           |
| BART    | [midas/gupshup_e2e_bart](https://huggingface.co/midas/gupshup_e2e_bart)       |
| GPT-2   | [midas/gupshup_e2e_gpt](https://huggingface.co/midas/gupshup_e2e_gpt)         |

## Inference

### Using command line
1. Clone this repo and Create a python virtual environment (https://docs.python.org/3/library/venv.html). Install the required pacakges using
```
pip install -r requirements.txt
```

2. run_eval script has following arguments. Run following command in terminal
*   **model_name** : one of our models avaialable on hugging face
*   **input_path** : Source file or path to file containing conversastions, which will be summarized. 
*   **save_path** : file path where to save summaries generated by model
*   **reference_path** : Target file or path to file containing summaries, to calculate metrices
*  **score_path** : file path where to save scores
*   **bs** : batch size
*   **device**:

Please make sure you have downloaded Gupshup dataset using above google form and provide correct path to these files in `input_path` and `refrence_path` of the argument. Or you can simply put `test.source` and `test.target` in `data/h2e/`(hinglish to english) or `data/e2e/`(english to english) folder. For example, to generate English summary from Hinglish dialogues using mbart model, run following command

```
python run_eval.py \
    --model_name midas/gupshup_h2e_mbart \
    --input_path  data/h2e/test.source \
    --save_path generated_summary.txt \
    --reference_path data/h2e/test.target \
    --score_path scores.txt \
    --bs 8

```

Another example, to generate English summary from English dialogues using Pegasus model
```
python run_eval.py \
    --model_name midas/gupshup_e2e_pegasus \
    --input_path  data/e2e/test.source \
    --save_path generated_summary.txt \
    --reference_path data/e2e/test.target \
    --score_path scores.txt \
    --bs 8

```

### In Google collaboratory

### Streamlit UI

2. use streamlit UI to make infrences from choice of your models and tasks. To start streamlit Server:
```
streamlit run app.py
```
3.

Please create an issue if you are facing any difficulties in replicating the results. 
